{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix ,classification_report, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas_profiling\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = pd.read_csv('Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_churn;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping \"CustomerID\" as it provides no signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn.drop(['customerID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing empty spaces with null values in \"TotalCharges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['TotalCharges'] = df_churn[\"TotalCharges\"].replace(\" \" , np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping nulls from \"TotalCharges\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = df_churn[df_churn[\"TotalCharges\"].notnull()]\n",
    "df_churn = df_churn.reset_index()[df_churn.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting strings to floats in \"TotalCharges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn[\"TotalCharges\"] = df_churn[\"TotalCharges\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replacing 'No internet service' to 'No' for columns which show 'No internet service'\n",
    "\n",
    "Making it more consistent, logically sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_columns = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport','StreamingTV', 'StreamingMovies']\n",
    "\n",
    "for i in replace_columns : \n",
    "    df_churn[i]  = df_churn[i].replace({'No internet service' : 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "''';\n",
    "    \n",
    "# #replace values\n",
    "# df_churn[\"SeniorCitizen\"] = df_churn[\"SeniorCitizen\"].replace({1:\"Yes\",0:\"No\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to bin tenures\n",
    "\n",
    "I might come back to this and rebin later. Especially curious about more bins to differntiate users with less than 2 years further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_tenure(df_churn):\n",
    "    \n",
    "    if df_churn[\"tenure\"] <= 12 :\n",
    "        return \"Tenure_0_to_12\"\n",
    "    elif (df_churn[\"tenure\"] > 12) & (df_churn[\"tenure\"] <= 24 ):\n",
    "        return \"Tenure_12_to_24\"\n",
    "    elif (df_churn[\"tenure\"] > 24) & (df_churn[\"tenure\"] <= 48) :\n",
    "        return \"Tenure_24_to_48\"\n",
    "    elif (df_churn[\"tenure\"] > 48) & (df_churn[\"tenure\"] <= 60) :\n",
    "        return \"Tenure_48_to_60\"\n",
    "    elif df_churn[\"tenure\"] > 60 :\n",
    "        return \"Tenure_60+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binning tenure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn[\"tenure_bin\"] = df_churn.apply(lambda df_churn:bin_tenure(df_churn), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_cols   = df_churn.nunique()[df_churn.nunique() <= 5].keys().tolist()\n",
    "# cat_cols;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating churn and non-churn\n",
    "df_only_churn     = df_churn[df_churn[\"Churn\"] == \"Yes\"]\n",
    "df_not_churn = df_churn[df_churn[\"Churn\"] == \"No\"]\n",
    "\n",
    "# Separating columns by numerical and categorical, target column is \"Churn\"\n",
    "target_col = [\"Churn\"]\n",
    "\n",
    "cat_cols   = df_churn.nunique()\n",
    "cat_cols   = df_churn.nunique()[df_churn.nunique() <= 5].keys().tolist()\n",
    "cat_cols   = [col for col in cat_cols if col not in target_col]\n",
    "num_cols   = [col for col in df_churn.columns if col not in cat_cols + target_col]\n",
    "\n",
    "\n",
    "# get binary columns with 2 values\n",
    "bin_cols   = df_churn.nunique()[df_churn.nunique() == 2].keys().tolist()\n",
    "# get columns with more than 2 values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing\n",
    "Standardizing the columns with numerical data, i.e. 'tenure', 'MonthlyCharges', 'TotalCharges'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "df_scaled = std.fit_transform(df_churn[num_cols])\n",
    "df_scaled = pd.DataFrame(df_scaled,columns=num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backup df as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_scaled.to_pickle(\"./df_churn.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the standardized columns into original df, dropping old values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn_scaled = df_churn.drop(columns = num_cols,axis = 1)\n",
    "df_churn_scaled = df_churn_scaled.merge(df_scaled,left_index=True,right_index=True,how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_churn_scaled;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn_scaled = pd.get_dummies(data = df_churn_scaled,columns = multi_cols, drop_first = True )\n",
    "df_churn_scaled = pd.get_dummies(data = df_churn_scaled,columns = bin_cols, drop_first = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle df_churn_scaled as backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_churn_scaled;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_churn_scaled.to_pickle(\"./df_churn_scaled_with_1_hot_encoding.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_churn_scaled = pd.read_pickle(\"./df_churn_scaled_with_1_hot_encoding.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val , test = train_test_split(df_churn_scaled,test_size = .20 ,random_state = 1988)\n",
    "train , val = train_test_split(train_val, test_size = .20 ,random_state = 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols    = [i for i in df_churn_scaled.columns if i not in target_col]\n",
    "\n",
    "target_col = [\"Churn_Yes\"]\n",
    "\n",
    "train_X = train[cols]\n",
    "train_Y = train[target_col]\n",
    "val_X = val[cols]\n",
    "val_Y = val[target_col]\n",
    "test_X  = test[cols]\n",
    "test_Y  = test[target_col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to show ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(test_y, preds, probs):\n",
    "    '''\n",
    "    plots ROC and prints out AUC\n",
    "    '''\n",
    "    model_roc_auc = roc_auc_score(test_y, preds) \n",
    "    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_y, probs[:,1])\n",
    "\n",
    "    plt.plot(fpr, tpr, lw = 2)\n",
    "    plt.plot([0,1],[0,1], c='violet', ls='--')\n",
    "    plt.xlim([-0.05,1.05])\n",
    "    plt.ylim([-0.05,1.05])\n",
    "\n",
    "\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compare baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_models_AUCs(train_x = train_X, test_x = val_X,\n",
    "                            train_y = train_Y, test_y = val_Y):\n",
    "    '''\n",
    "    This function prints out the AUCs for all baseline models.\n",
    "    It returns a dict with all the models as keys, and the AUCs as values.\n",
    "    '''\n",
    "    result = {}\n",
    "    models = {\"Logistic Regression\" : LogisticRegression(), \n",
    "              \"KNN\" : KNeighborsClassifier(n_neighbors = 6),\n",
    "              \"Support Vector Classifier\" : SVC(probability=True),\n",
    "              \"Random Forest\": RandomForestClassifier(random_state= 31),\n",
    "              \"Gaussian Naive Bayes\" : GaussianNB(),\n",
    "#               \"Multinomial Naive Bayes\" : MultinomialNB(),\n",
    "              \"Light GBM Classifier\" : LGBMClassifier(),\n",
    "              \"XGBoost Classifier\" : XGBClassifier()\n",
    "             }\n",
    "    \n",
    "    for key, algorithm in models.items():\n",
    "        algorithm.fit(train_x, train_y)\n",
    "        predictions   = algorithm.predict(test_x)\n",
    "        probabilities = algorithm.predict_proba(test_x)\n",
    "        model_roc_auc = roc_auc_score(test_y, predictions) \n",
    "        print (f'{key} :  {model_roc_auc}\\n')\n",
    "        result[key] = model_roc_auc\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :  0.701724124594881\n",
      "\n",
      "KNN :  0.6520269486320707\n",
      "\n",
      "Support Vector Classifier :  0.6595221336138549\n",
      "\n",
      "Random Forest :  0.6411805883217438\n",
      "\n",
      "Gaussian Naive Bayes :  0.7630121516363327\n",
      "\n",
      "Light GBM Classifier :  0.688048699364959\n",
      "\n",
      "XGBoost Classifier :  0.6961433444459055\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.701724124594881,\n",
       " 'KNN': 0.6520269486320707,\n",
       " 'Support Vector Classifier': 0.6595221336138549,\n",
       " 'Random Forest': 0.6411805883217438,\n",
       " 'Gaussian Naive Bayes': 0.7630121516363327,\n",
       " 'Light GBM Classifier': 0.688048699364959,\n",
       " 'XGBoost Classifier': 0.6961433444459055}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_baseline_models_AUCs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_prediction_coefs(cols, cf, algorithm = LogisticRegression(), \n",
    "                                train_x = train_X , test_x = val_X ,\n",
    "                                train_y = train_Y ,test_y = val_Y ) :\n",
    "    \n",
    "    '''\n",
    "    This function fits the model, prints a summary including AUC curve, accuracy score, F1 score\n",
    "    It also produces 3 plotly graphs: A confusion matrix, an ROC curve, and a bar graph showing\n",
    "    feature importance for each feature.\n",
    "    \n",
    "    INPUT:\n",
    "    It takes columns, algorithm, train_df for x and y, test_df for x and y bas inputs\n",
    "    \n",
    "    cf is an input string that is either \"coefficients\" or \"features\"\n",
    "    \n",
    "    DEFAULT:\n",
    "    Its default algorithm is LogisticRegression()\n",
    "    default train dfs are train_X and train_Y\n",
    "    default test dfs are val_X and val_Y\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    algorithm.fit(train_x, train_y)\n",
    "    \n",
    "    predictions   = algorithm.predict(test_x)  \n",
    "    probabilities = algorithm.predict_proba(test_x)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_y, probabilities[:,1])\n",
    "    \n",
    "    if   cf == \"coefficients\":\n",
    "        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n",
    "    elif cf == \"features\":\n",
    "        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n",
    "        \n",
    "    column_df       = pd.DataFrame(cols)\n",
    "    coef_summary    = (pd.merge(coefficients,column_df,left_index= True,\n",
    "                              right_index= True, how = \"left\"))\n",
    "    coef_summary.columns = [\"coefficients\",\"features\"]\n",
    "    coef_summary    = coef_summary.sort_values(by = \"coefficients\",ascending = False)\n",
    "    \n",
    "    print(\"_____________________________________________________________\")   \n",
    "    print(\"\\n Results : \\n\", classification_report(test_y,predictions))\n",
    "    print(\"Accuracy - score : \", accuracy_score(test_y,predictions))\n",
    "    \n",
    "    \n",
    "    conf_matrix = confusion_matrix(test_y,predictions)\n",
    "    \n",
    "    \n",
    "\n",
    "    # making roc curve, redundant\n",
    "#     plot_roc(test_y, preds = predictions, probs = probabilities)\n",
    "    \n",
    "    # this can be commented out if using non-plotly roc curve above: plot_roc()\n",
    "    model_roc_auc = roc_auc_score(test_y, predictions) \n",
    "    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n",
    "    \n",
    "    fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n",
    "                            subplot_titles=('Confusion Matrix',\n",
    "                                            'Receiver operating characteristic',\n",
    "                                            'Feature Importances'),\n",
    "                            print_grid=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    bars = go.Bar(x = coef_summary[\"features\"], y = coef_summary[\"coefficients\"],\n",
    "                    name = \"coefficients\",\n",
    "                    marker = dict(color = coef_summary[\"coefficients\"],\n",
    "                                  colorscale = \"Jet\",\n",
    "                                  line = dict(width = .6, color = \"black\")))\n",
    "    \n",
    "    roc_line = go.Scatter(x = fpr, y = tpr,\n",
    "                        name = \"Roc : \" + str(model_roc_auc),\n",
    "                        line = dict(color = ('rgb(25, 96, 167)'),width = 2))\n",
    "    \n",
    "    roc_stand = go.Scatter(x = [0,1],y=[0,1],\n",
    "                        line = dict(color = ('rgb(215, 12, 24)'),width = 2,\n",
    "                        dash = 'dot'))\n",
    "    \n",
    "    c_matrix = go.Heatmap(z = conf_matrix ,\n",
    "                        x = [\"Non churn\",\"Churn\"],\n",
    "                        y = [\"Non churn\",\"Churn\"],\n",
    "                        showscale  = False, colorscale = \"Jet\",\n",
    "                        name = \"matrix\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig.append_trace(bars,2,1)\n",
    "    fig.append_trace(roc_line,1,2)\n",
    "    fig.append_trace(c_matrix,1,1)\n",
    "    fig.append_trace(roc_stand,1,2)\n",
    "    \n",
    "    fig['layout'].update(showlegend = False, title=\"Model performance\" ,\n",
    "                         autosize = False,height = 1000,width = 850,\n",
    "                         plot_bgcolor = 'rgba(230,230,230, 0.95)',\n",
    "                         paper_bgcolor = 'rgba(230,230,230, 0.95)',\n",
    "                         margin = dict(b = 185))\n",
    "    \n",
    "    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n",
    "    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n",
    "    fig[\"layout\"][\"xaxis1\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n",
    "                                        tickangle = 90))\n",
    "#     print('\\nConfusion Matrix:')\n",
    "#     print(conf_matrix)\n",
    "    \n",
    "    \n",
    "    return(algorithm, py.iplot(fig, filename = 'jupyter-table1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________\n",
      "\n",
      " Results : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       803\n",
      "           1       0.65      0.52      0.57       322\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1125\n",
      "   macro avg       0.73      0.70      0.71      1125\n",
      "weighted avg       0.77      0.78      0.77      1125\n",
      "\n",
      "Accuracy - score :  0.7813333333333333\n",
      "Area under curve :  0.701724124594881 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~leoknauth/114.embed\" height=\"1000px\" width=\"850px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logit_model, logit_graph) = make_model_prediction_coefs(cols = cols, cf = \"coefficients\")\n",
    "logit_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm = 'auto', leaf_size=30,\n",
    "           metric_params = None, n_jobs=-1, n_neighbors = 6, p = 2,\n",
    "           weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knn   = knn.predict(val_X)\n",
    "probabilities_knn = knn.predict_proba(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Classification report: \\n\",classification_report(val_Y ,predictions_knn))\n",
    "print(\"Accuracy Score: \",accuracy_score(val_Y ,predictions_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(val_Y = val_Y, preds = predictions_knn, probs = probabilities_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_SMOTE, train_Y_SMOTE = SMOTE(random_state = 1911).fit_sample(train_X, train_Y)\n",
    "val_X_SMOTE, val_Y_SMOTE = SMOTE(random_state = 1911).fit_sample(val_X, val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________\n",
      "\n",
      " Results : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       803\n",
      "           1       0.74      0.81      0.77       803\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1606\n",
      "   macro avg       0.76      0.76      0.76      1606\n",
      "weighted avg       0.76      0.76      0.76      1606\n",
      "\n",
      "Accuracy - score :  0.7615193026151931\n",
      "Area under curve :  0.7615193026151931 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~leoknauth/110.embed\" height=\"1000px\" width=\"850px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logit_model_smote, logit_graph_smote) = make_model_prediction_coefs(cols = cols, cf = \"coefficients\", \n",
    "                                                                     train_x =train_X_SMOTE, train_y = train_Y_SMOTE, \n",
    "                                                                     test_x = val_X_SMOTE, test_y = val_Y_SMOTE)\n",
    "logit_graph_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :  0.7615193026151931\n",
      "\n",
      "KNN :  0.7098381070983811\n",
      "\n",
      "Support Vector Classifier :  0.7770859277708593\n",
      "\n",
      "Random Forest :  0.7571606475716064\n",
      "\n",
      "Gaussian Naive Bayes :  0.772104607721046\n",
      "\n",
      "Light GBM Classifier :  0.8337484433374845\n",
      "\n",
      "XGBoost Classifier :  0.8356164383561643\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.7615193026151931,\n",
       " 'KNN': 0.7098381070983811,\n",
       " 'Support Vector Classifier': 0.7770859277708593,\n",
       " 'Random Forest': 0.7571606475716064,\n",
       " 'Gaussian Naive Bayes': 0.772104607721046,\n",
       " 'Light GBM Classifier': 0.8337484433374845,\n",
       " 'XGBoost Classifier': 0.8356164383561643}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_baseline_models_AUCs(train_x = train_X_SMOTE, test_x = val_X_SMOTE,\n",
    "                            train_y = train_Y_SMOTE, test_y = val_Y_SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE lead to an increased performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ADASYN, train_Y_ADASYN = ADASYN(random_state = 1990).fit_sample(train_X, train_Y)\n",
    "val_X_ADASYN, val_Y_ADASYN = ADASYN(random_state = 1990).fit_sample(val_X, val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________\n",
      "\n",
      " Results : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.63      0.70       803\n",
      "           1       0.69      0.82      0.75       787\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      1590\n",
      "   macro avg       0.74      0.73      0.72      1590\n",
      "weighted avg       0.74      0.73      0.72      1590\n",
      "\n",
      "Accuracy - score :  0.7257861635220125\n",
      "Area under curve :  0.726758455031244 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~leoknauth/112.embed\" height=\"1000px\" width=\"850px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logit_model_adasyn, logit_graph_adasyn) = make_model_prediction_coefs(cols = cols, cf = \"coefficients\", \n",
    "                                                                     train_x =train_X_ADASYN, train_y = train_Y_ADASYN, \n",
    "                                                                     test_x = val_X_ADASYN, test_y = val_Y_ADASYN)\n",
    "logit_graph_adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :  0.726758455031244\n",
      "\n",
      "KNN :  0.6978144220925026\n",
      "\n",
      "Support Vector Classifier :  0.7441527246143353\n",
      "\n",
      "Random Forest :  0.7609211644389449\n",
      "\n",
      "Gaussian Naive Bayes :  0.7491490772373612\n",
      "\n",
      "Light GBM Classifier :  0.8281768969920612\n",
      "\n",
      "XGBoost Classifier :  0.836803220451895\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.726758455031244,\n",
       " 'KNN': 0.6978144220925026,\n",
       " 'Support Vector Classifier': 0.7441527246143353,\n",
       " 'Random Forest': 0.7609211644389449,\n",
       " 'Gaussian Naive Bayes': 0.7491490772373612,\n",
       " 'Light GBM Classifier': 0.8281768969920612,\n",
       " 'XGBoost Classifier': 0.836803220451895}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_baseline_models_AUCs(train_x = train_X_ADASYN, test_x = val_X_ADASYN,\n",
    "                            train_y = train_Y_ADASYN, test_y = val_Y_ADASYN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADASYN doesn't do as well was SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
