{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix ,classification_report, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,scorer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas_profiling\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = pd.read_csv('Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_churn;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping \"CustomerID\" as it provides no signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn.drop(['customerID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing empty spaces with null values in \"TotalCharges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['TotalCharges'] = df_churn[\"TotalCharges\"].replace(\" \" , np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping nulls from \"TotalCharges\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = df_churn[df_churn[\"TotalCharges\"].notnull()]\n",
    "df_churn = df_churn.reset_index()[df_churn.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting strings to floats in \"TotalCharges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn[\"TotalCharges\"] = df_churn[\"TotalCharges\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replacing 'No internet service' to 'No' for columns which show 'No internet service'\n",
    "\n",
    "Making it more consistent, logically sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_columns = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport','StreamingTV', 'StreamingMovies']\n",
    "\n",
    "for i in replace_columns : \n",
    "    df_churn[i]  = df_churn[i].replace({'No internet service' : 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "''';\n",
    "    \n",
    "# #replace values\n",
    "# df_churn[\"SeniorCitizen\"] = df_churn[\"SeniorCitizen\"].replace({1:\"Yes\",0:\"No\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to bin tenures\n",
    "\n",
    "I might come back to this and rebin later. Especially curious about more bins to differntiate users with less than 2 years further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_tenure(df_churn):\n",
    "    \n",
    "    '''\n",
    "    helper function to be able to come back later and change bins\n",
    "    '''\n",
    "    \n",
    "    if df_churn[\"tenure\"] <= 12 :\n",
    "        return \"Tenure_0_to_12\"\n",
    "    elif (df_churn[\"tenure\"] > 12) & (df_churn[\"tenure\"] <= 24 ):\n",
    "        return \"Tenure_12_to_24\"\n",
    "    elif (df_churn[\"tenure\"] > 24) & (df_churn[\"tenure\"] <= 48) :\n",
    "        return \"Tenure_24_to_48\"\n",
    "    elif (df_churn[\"tenure\"] > 48) & (df_churn[\"tenure\"] <= 60) :\n",
    "        return \"Tenure_48_to_60\"\n",
    "    elif df_churn[\"tenure\"] > 60 :\n",
    "        return \"Tenure_60+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binning tenure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn[\"tenure_bin\"] = df_churn.apply(lambda df_churn:bin_tenure(df_churn), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_cols   = df_churn.nunique()[df_churn.nunique() <= 5].keys().tolist()\n",
    "# cat_cols;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating churn and non-churn\n",
    "df_only_churn     = df_churn[df_churn[\"Churn\"] == \"Yes\"]\n",
    "df_not_churn = df_churn[df_churn[\"Churn\"] == \"No\"]\n",
    "\n",
    "# Separating columns by numerical and categorical, target column is \"Churn\"\n",
    "target_col = [\"Churn\"]\n",
    "\n",
    "cat_cols   = df_churn.nunique()\n",
    "cat_cols   = df_churn.nunique()[df_churn.nunique() <= 5].keys().tolist()\n",
    "cat_cols   = [col for col in cat_cols if col not in target_col]\n",
    "num_cols   = [col for col in df_churn.columns if col not in cat_cols + target_col]\n",
    "\n",
    "\n",
    "# get binary columns with 2 values\n",
    "bin_cols   = df_churn.nunique()[df_churn.nunique() == 2].keys().tolist()\n",
    "# get columns with more than 2 values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_scaled.to_pickle(\"./df_churn.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the standardized columns into original df, dropping old values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_churn_scaled = df_churn.drop(columns = num_cols,axis = 1)\n",
    "# df_churn_scaled = df_churn_scaled.merge(df_scaled,left_index=True,right_index=True,how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_churn_scaled;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn_encoded = pd.get_dummies(data = df_churn,columns = multi_cols, drop_first = True )\n",
    "df_churn_encoded = pd.get_dummies(data = df_churn,columns = bin_cols, drop_first = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle df_churn_scaled as backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>tenure_bin</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>SeniorCitizen_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>OnlineSecurity_Yes</th>\n",
       "      <th>OnlineBackup_Yes</th>\n",
       "      <th>DeviceProtection_Yes</th>\n",
       "      <th>TechSupport_Yes</th>\n",
       "      <th>StreamingTV_Yes</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <th>Churn_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>Tenure_0_to_12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>One year</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>Tenure_24_to_48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Tenure_0_to_12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>One year</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>Tenure_24_to_48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Tenure_0_to_12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure     MultipleLines InternetService        Contract  \\\n",
       "0       1  No phone service             DSL  Month-to-month   \n",
       "1      34                No             DSL        One year   \n",
       "2       2                No             DSL  Month-to-month   \n",
       "3      45  No phone service             DSL        One year   \n",
       "4       2                No     Fiber optic  Month-to-month   \n",
       "\n",
       "               PaymentMethod  MonthlyCharges  TotalCharges       tenure_bin  \\\n",
       "0           Electronic check           29.85         29.85   Tenure_0_to_12   \n",
       "1               Mailed check           56.95       1889.50  Tenure_24_to_48   \n",
       "2               Mailed check           53.85        108.15   Tenure_0_to_12   \n",
       "3  Bank transfer (automatic)           42.30       1840.75  Tenure_24_to_48   \n",
       "4           Electronic check           70.70        151.65   Tenure_0_to_12   \n",
       "\n",
       "   gender_Male  SeniorCitizen_1  ...  Dependents_Yes  PhoneService_Yes  \\\n",
       "0            0                0  ...               0                 0   \n",
       "1            1                0  ...               0                 1   \n",
       "2            1                0  ...               0                 1   \n",
       "3            1                0  ...               0                 0   \n",
       "4            0                0  ...               0                 1   \n",
       "\n",
       "   OnlineSecurity_Yes  OnlineBackup_Yes  DeviceProtection_Yes  \\\n",
       "0                   0                 1                     0   \n",
       "1                   1                 0                     1   \n",
       "2                   1                 1                     0   \n",
       "3                   1                 0                     1   \n",
       "4                   0                 0                     0   \n",
       "\n",
       "   TechSupport_Yes  StreamingTV_Yes  StreamingMovies_Yes  \\\n",
       "0                0                0                    0   \n",
       "1                0                0                    0   \n",
       "2                0                0                    0   \n",
       "3                1                0                    0   \n",
       "4                0                0                    0   \n",
       "\n",
       "   PaperlessBilling_Yes  Churn_Yes  \n",
       "0                     1          0  \n",
       "1                     0          0  \n",
       "2                     1          1  \n",
       "3                     0          0  \n",
       "4                     1          1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_churn_scaled.to_pickle(\"./df_churn_scaled_with_1_hot_encoding.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_churn_scaled = pd.read_pickle(\"./df_churn_scaled_with_1_hot_encoding.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>tenure_bin</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>SeniorCitizen_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>OnlineSecurity_Yes</th>\n",
       "      <th>OnlineBackup_Yes</th>\n",
       "      <th>DeviceProtection_Yes</th>\n",
       "      <th>TechSupport_Yes</th>\n",
       "      <th>StreamingTV_Yes</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <th>Churn_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>Tenure_0_to_12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>One year</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>Tenure_24_to_48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Tenure_0_to_12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>One year</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>Tenure_24_to_48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Tenure_0_to_12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure     MultipleLines InternetService        Contract  \\\n",
       "0       1  No phone service             DSL  Month-to-month   \n",
       "1      34                No             DSL        One year   \n",
       "2       2                No             DSL  Month-to-month   \n",
       "3      45  No phone service             DSL        One year   \n",
       "4       2                No     Fiber optic  Month-to-month   \n",
       "\n",
       "               PaymentMethod  MonthlyCharges  TotalCharges       tenure_bin  \\\n",
       "0           Electronic check           29.85         29.85   Tenure_0_to_12   \n",
       "1               Mailed check           56.95       1889.50  Tenure_24_to_48   \n",
       "2               Mailed check           53.85        108.15   Tenure_0_to_12   \n",
       "3  Bank transfer (automatic)           42.30       1840.75  Tenure_24_to_48   \n",
       "4           Electronic check           70.70        151.65   Tenure_0_to_12   \n",
       "\n",
       "   gender_Male  SeniorCitizen_1  ...  Dependents_Yes  PhoneService_Yes  \\\n",
       "0            0                0  ...               0                 0   \n",
       "1            1                0  ...               0                 1   \n",
       "2            1                0  ...               0                 1   \n",
       "3            1                0  ...               0                 0   \n",
       "4            0                0  ...               0                 1   \n",
       "\n",
       "   OnlineSecurity_Yes  OnlineBackup_Yes  DeviceProtection_Yes  \\\n",
       "0                   0                 1                     0   \n",
       "1                   1                 0                     1   \n",
       "2                   1                 1                     0   \n",
       "3                   1                 0                     1   \n",
       "4                   0                 0                     0   \n",
       "\n",
       "   TechSupport_Yes  StreamingTV_Yes  StreamingMovies_Yes  \\\n",
       "0                0                0                    0   \n",
       "1                0                0                    0   \n",
       "2                0                0                    0   \n",
       "3                1                0                    0   \n",
       "4                0                0                    0   \n",
       "\n",
       "   PaperlessBilling_Yes  Churn_Yes  \n",
       "0                     1          0  \n",
       "1                     0          0  \n",
       "2                     1          1  \n",
       "3                     0          0  \n",
       "4                     1          1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_churn_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val , test = train_test_split(df_churn_encoded,test_size = .20 ,random_state = 1988)\n",
    "train , val = train_test_split(train_val, test_size = .20 ,random_state = 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = [\"Churn_Yes\"]\n",
    "\n",
    "cols    = [i for i in df_churn_encoded.columns if i not in target_col]\n",
    "\n",
    "\n",
    "train_val_X = train_val[cols]\n",
    "train_val_Y = train_val[target_col]\n",
    "train_X = train[cols]\n",
    "train_Y = train[target_col]\n",
    "val_X = val[cols]\n",
    "val_Y = val[target_col]\n",
    "test_X  = test[cols]\n",
    "test_Y  = test[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_val_X;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing\n",
    "Standardizing the columns with numerical data, i.e. 'tenure', 'MonthlyCharges', 'TotalCharges'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "\n",
    "train_val_scaled_X = std.fit_transform(train_val_X[num_cols])\n",
    "train_val_scaled_X = pd.DataFrame(train_val_scaled_X , columns=num_cols )\n",
    "\n",
    "train_scaled_X = std.fit_transform(train_X[num_cols])\n",
    "train_scaled_X = pd.DataFrame(train_scaled_X , columns=num_cols )\n",
    "\n",
    "val_scaled_X = std.fit_transform(val_X[num_cols])\n",
    "val_scaled_X = pd.DataFrame(val_scaled_X , columns=num_cols )\n",
    "\n",
    "test_scaled_X = std.fit_transform(test_X[num_cols])\n",
    "test_scaled_X = pd.DataFrame(test_scaled_X , columns=num_cols )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the standardized columns into original dfs, dropping old values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_final_X = train_val_X.drop(columns = num_cols,axis = 1)\n",
    "train_val_final_X = train_val_final_X.merge(train_val_scaled_X,left_index=True,right_index=True,how = \"left\")\n",
    "\n",
    "train_final_X = train_val_X.drop(columns = num_cols,axis = 1)\n",
    "train_final_X = train_val_final_X.merge(train_scaled_X,left_index=True,right_index=True,how = \"left\")\n",
    "\n",
    "val_final_X = train_val_X.drop(columns = num_cols,axis = 1)\n",
    "val_final_X = train_val_final_X.merge(val_scaled_X,left_index=True,right_index=True,how = \"left\")\n",
    "\n",
    "test_final_X = train_val_X.drop(columns = num_cols,axis = 1)\n",
    "test_final_X = train_val_final_X.merge(test_scaled_X,left_index=True,right_index=True,how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>tenure_bin</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>SeniorCitizen_1</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>...</th>\n",
       "      <th>TechSupport_Yes</th>\n",
       "      <th>StreamingTV_Yes</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <th>tenure_x</th>\n",
       "      <th>MonthlyCharges_x</th>\n",
       "      <th>TotalCharges_x</th>\n",
       "      <th>tenure_y</th>\n",
       "      <th>MonthlyCharges_y</th>\n",
       "      <th>TotalCharges_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>One year</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>Tenure_60+</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844395</td>\n",
       "      <td>1.036080</td>\n",
       "      <td>1.216201</td>\n",
       "      <td>0.085465</td>\n",
       "      <td>-1.461528</td>\n",
       "      <td>-0.712187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>Tenure_0_to_12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109984</td>\n",
       "      <td>1.220905</td>\n",
       "      <td>0.543147</td>\n",
       "      <td>-1.292520</td>\n",
       "      <td>0.307279</td>\n",
       "      <td>-0.984549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5510</th>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>Tenure_0_to_12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640392</td>\n",
       "      <td>-1.483195</td>\n",
       "      <td>-0.550181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>One year</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>Tenure_48_to_60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.032433</td>\n",
       "      <td>0.824614</td>\n",
       "      <td>-0.705409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>Tenure_0_to_12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803594</td>\n",
       "      <td>1.031085</td>\n",
       "      <td>1.198444</td>\n",
       "      <td>-1.211462</td>\n",
       "      <td>-0.674475</td>\n",
       "      <td>-0.963516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MultipleLines InternetService        Contract     PaymentMethod  \\\n",
       "467            Yes     Fiber optic        One year  Electronic check   \n",
       "593             No             DSL  Month-to-month      Mailed check   \n",
       "5510            No             DSL  Month-to-month      Mailed check   \n",
       "2665           Yes     Fiber optic        One year      Mailed check   \n",
       "752             No     Fiber optic  Month-to-month  Electronic check   \n",
       "\n",
       "           tenure_bin  gender_Male  SeniorCitizen_1  Partner_Yes  \\\n",
       "467        Tenure_60+            1                0            1   \n",
       "593    Tenure_0_to_12            1                0            0   \n",
       "5510   Tenure_0_to_12            1                0            1   \n",
       "2665  Tenure_48_to_60            0                0            1   \n",
       "752    Tenure_0_to_12            0                0            1   \n",
       "\n",
       "      Dependents_Yes  PhoneService_Yes  ...  TechSupport_Yes  StreamingTV_Yes  \\\n",
       "467                1                 1  ...                0                1   \n",
       "593                0                 1  ...                0                0   \n",
       "5510               0                 1  ...                0                0   \n",
       "2665               1                 1  ...                1                1   \n",
       "752                0                 1  ...                0                1   \n",
       "\n",
       "      StreamingMovies_Yes  PaperlessBilling_Yes  tenure_x  MonthlyCharges_x  \\\n",
       "467                     0                     1  0.844395          1.036080   \n",
       "593                     0                     0  0.109984          1.220905   \n",
       "5510                    0                     0  0.640392         -1.483195   \n",
       "2665                    0                     1 -1.032433          0.824614   \n",
       "752                     0                     0  0.803594          1.031085   \n",
       "\n",
       "      TotalCharges_x  tenure_y  MonthlyCharges_y  TotalCharges_y  \n",
       "467         1.216201  0.085465         -1.461528       -0.712187  \n",
       "593         0.543147 -1.292520          0.307279       -0.984549  \n",
       "5510       -0.550181       NaN               NaN             NaN  \n",
       "2665       -0.705409       NaN               NaN             NaN  \n",
       "752         1.198444 -1.211462         -0.674475       -0.963516  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backup df as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to show ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(test_y, preds, probs):\n",
    "    '''\n",
    "    plots ROC and prints out AUC\n",
    "    '''\n",
    "    model_roc_auc = roc_auc_score(test_y, preds) \n",
    "    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_y, probs[:,1])\n",
    "\n",
    "    plt.plot(fpr, tpr, lw = 2)\n",
    "    plt.plot([0,1],[0,1], c='violet', ls='--')\n",
    "    plt.xlim([-0.05,1.05])\n",
    "    plt.ylim([-0.05,1.05])\n",
    "\n",
    "\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to make predictions and return ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_ROC_AUC(algorithm, test_x, test_y):\n",
    "    '''\n",
    "    Input is a model that has been .fit(), and the dfs for test_x and test_y\n",
    "    \n",
    "    returns ROC AUC\n",
    "    '''\n",
    "    \n",
    "    predictions   = algorithm.predict(test_x)\n",
    "    probabilities = algorithm.predict_proba(test_x)\n",
    "    model_roc_auc = roc_auc_score(test_y, predictions)\n",
    "    return model_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compare baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_models_AUCs(train_x = train_X, test_x = val_X,\n",
    "                            train_y = train_Y, test_y = val_Y):\n",
    "    '''\n",
    "    This function prints out the AUCs for all baseline models.\n",
    "    It returns a dict with all the models as keys, and the AUCs as values.\n",
    "    '''\n",
    "    result = {}\n",
    "    models = {\"Logistic Regression\" : LogisticRegression(), \n",
    "              \"KNN\" : KNeighborsClassifier(n_neighbors = 6),\n",
    "              \"Support Vector Classifier\" : SVC(probability=True),\n",
    "              \"Random Forest\": RandomForestClassifier(random_state= 31),\n",
    "              \"Gaussian Naive Bayes\" : GaussianNB(),\n",
    "#               \"Multinomial Naive Bayes\" : MultinomialNB(),\n",
    "              \"Gradient Boost Classifier\" : GradientBoostingClassifier(),\n",
    "              \"Light GBM Classifier\" : LGBMClassifier(),\n",
    "              \"XGBoost Classifier\" : XGBClassifier()\n",
    "              \n",
    "             }\n",
    "    \n",
    "    for key, algorithm in models.items():\n",
    "        fit_model = algorithm.fit(train_x, train_y)\n",
    "        model_roc_auc = get_model_ROC_AUC(fit_model, test_x, test_y)\n",
    "        print (f'{key} :  {model_roc_auc}\\n')\n",
    "        result[key] = model_roc_auc\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :  0.701724124594881\n",
      "\n",
      "KNN :  0.6520269486320707\n",
      "\n",
      "Support Vector Classifier :  0.6595221336138549\n",
      "\n",
      "Random Forest :  0.6411805883217438\n",
      "\n",
      "Gaussian Naive Bayes :  0.7630121516363327\n",
      "\n",
      "Gradient Boost Classifier :  0.6955129444706574\n",
      "\n",
      "Light GBM Classifier :  0.688048699364959\n",
      "\n",
      "XGBoost Classifier :  0.6961433444459055\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.701724124594881,\n",
       " 'KNN': 0.6520269486320707,\n",
       " 'Support Vector Classifier': 0.6595221336138549,\n",
       " 'Random Forest': 0.6411805883217438,\n",
       " 'Gaussian Naive Bayes': 0.7630121516363327,\n",
       " 'Gradient Boost Classifier': 0.6955129444706574,\n",
       " 'Light GBM Classifier': 0.688048699364959,\n",
       " 'XGBoost Classifier': 0.6961433444459055}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_baseline_models_AUCs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correlation_matrix(df = df_churn):   \n",
    "    '''\n",
    "    produces a plotly correlation matrix\n",
    "    \n",
    "    INPUT: dataframe\n",
    "    \n",
    "    RETURNS: the plotly plot.\n",
    "    \n",
    "    NOTE: you need to store the output of this function in a cariable, \n",
    "    and then put that in a new line to see the plot.\n",
    "    like so:\n",
    "\n",
    "    out = make_correlation_matrix(df_churn_scaled)\n",
    "    out\n",
    "    \n",
    "    '''\n",
    "    correlations = df.corr()\n",
    "    matrix_columns = correlations.columns.tolist()\n",
    "    corr_array  = np.array(correlations)\n",
    "\n",
    "    \n",
    "    heat = go.Heatmap(z = corr_array,\n",
    "                        x = matrix_columns,\n",
    "                        y = matrix_columns,\n",
    "                        colorscale = \"Jet\",\n",
    "                        colorbar   = dict(title = \"Pearson correlation coefficient\",\n",
    "                                         titleside = \"right\"\n",
    "                                        ) ,\n",
    "                      )\n",
    "\n",
    "    layout = go.Layout(dict(title = \"Correlation Matrix\",\n",
    "                            \n",
    "                            height  = 600,\n",
    "                            width   = 800,\n",
    "                            margin  = dict(r = 0 ,l = 200,\n",
    "                                           t = 25,b = 200,\n",
    "                                          ),\n",
    "                            yaxis   = dict(tickfont = dict(size = 10)),\n",
    "                            xaxis   = dict(tickfont = dict(size = 10))\n",
    "                           )\n",
    "                      )\n",
    "\n",
    "    fig = go.Figure(data= [heat],layout=layout)\n",
    "    return py.iplot(fig, filename = 'correlation-matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~leoknauth/122.embed\" height=\"600px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = make_correlation_matrix(df_churn_scaled)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_prediction_coefs(cols, cf, algorithm = LogisticRegression(), \n",
    "                                train_x = train_X , test_x = val_X ,\n",
    "                                train_y = train_Y ,test_y = val_Y ) :\n",
    "    \n",
    "    '''\n",
    "    This function fits the model, prints a summary including AUC curve, accuracy score, F1 score\n",
    "    It also produces 3 plotly graphs: A confusion matrix, an ROC curve, and a bar graph showing\n",
    "    feature importance for each feature.\n",
    "    \n",
    "    INPUT:\n",
    "    It takes columns, algorithm, train_df for x and y, test_df for x and y bas inputs\n",
    "    \n",
    "    cf is an input string that is either \"coefficients\" or \"features\"\n",
    "    \n",
    "    RETURNS: A tuple of (model, pyplot object)\n",
    "    \n",
    "    DEFAULT:\n",
    "    Its default algorithm is LogisticRegression()\n",
    "    default train dfs are train_X and train_Y\n",
    "    default test dfs are val_X and val_Y\n",
    "    \n",
    "    NOTE: you need to store the output of this function in a variable, \n",
    "    and then put that in a new line to see the plot.\n",
    "    like so:\n",
    "    \n",
    "    (logit_model, logit_graph) = make_model_prediction_coefs(cols = cols, cf = \"coefficients\")\n",
    "    logit_graph\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    algorithm.fit(train_x, train_y)\n",
    "    \n",
    "    predictions   = algorithm.predict(test_x)  \n",
    "    probabilities = algorithm.predict_proba(test_x)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_y, probabilities[:,1])\n",
    "    \n",
    "    if   cf == \"coefficients\":\n",
    "        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n",
    "    elif cf == \"features\":\n",
    "        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n",
    "        \n",
    "    column_df       = pd.DataFrame(cols)\n",
    "    coef_summary    = (pd.merge(coefficients,column_df,left_index= True,\n",
    "                              right_index= True, how = \"left\"))\n",
    "    coef_summary.columns = [\"coefficients\",\"features\"]\n",
    "    coef_summary    = coef_summary.sort_values(by = \"coefficients\",ascending = False)\n",
    "    \n",
    "    print(\"_____________________________________________________________\")   \n",
    "    print(\"\\n Results : \\n\", classification_report(test_y,predictions))\n",
    "    print(\"Accuracy - score : \", accuracy_score(test_y,predictions))\n",
    "    \n",
    "    \n",
    "    conf_matrix = confusion_matrix(test_y,predictions)\n",
    "    \n",
    "    \n",
    "\n",
    "    # making roc curve, redundant\n",
    "#     plot_roc(test_y, preds = predictions, probs = probabilities)\n",
    "    \n",
    "    # this can be commented out if using non-plotly roc curve above: plot_roc()\n",
    "    \n",
    "    model_roc_auc = roc_auc_score(test_y, predictions) \n",
    "    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n",
    "    \n",
    "    fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n",
    "                            subplot_titles=('Confusion Matrix',\n",
    "                                            'Receiver operating characteristic',\n",
    "                                            'Feature Importances'),\n",
    "                            print_grid=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    bars = go.Bar(x = coef_summary[\"features\"], y = coef_summary[\"coefficients\"],\n",
    "                    name = \"coefficients\",\n",
    "                    marker = dict(color = coef_summary[\"coefficients\"],\n",
    "                                  colorscale = \"Jet\",\n",
    "                                  line = dict(width = .6, color = \"black\")))\n",
    "    \n",
    "    roc_line = go.Scatter(x = fpr, y = tpr,\n",
    "                        name = \"Roc : \" + str(model_roc_auc),\n",
    "                        line = dict(color = ('rgb(25, 96, 167)'),width = 2))\n",
    "    \n",
    "    roc_stand = go.Scatter(x = [0,1],y=[0,1],\n",
    "                        line = dict(color = ('rgb(215, 12, 24)'),width = 2,\n",
    "                        dash = 'dot'))\n",
    "    \n",
    "    c_matrix = go.Heatmap(z = conf_matrix ,\n",
    "                        x = [\"Non churn\",\"Churn\"],\n",
    "                        y = [\"Non churn\",\"Churn\"],\n",
    "                        showscale  = False, colorscale = \"Jet\",\n",
    "                        name = \"matrix\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig.append_trace(bars,2,1)\n",
    "    fig.append_trace(roc_line,1,2)\n",
    "    fig.append_trace(c_matrix,1,1)\n",
    "    fig.append_trace(roc_stand,1,2)\n",
    "    \n",
    "    fig['layout'].update(showlegend = False, title=\"Model performance\" ,\n",
    "                         autosize = False,height = 1000,width = 850,\n",
    "                         plot_bgcolor = 'rgba(250,250,250, 0.95)',\n",
    "                         paper_bgcolor = 'rgba(250,250,250, 0.95)',\n",
    "                         margin = dict(b = 185))\n",
    "    \n",
    "    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n",
    "    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n",
    "    fig[\"layout\"][\"xaxis1\"].update(dict(showgrid = True,tickfont = dict(size = 12),\n",
    "                                        tickangle = 0))\n",
    "#     print('\\nConfusion Matrix:')\n",
    "#     print(conf_matrix)\n",
    "    \n",
    "    \n",
    "    return(algorithm, py.iplot(fig, filename = 'jupyter-table1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________\n",
      "\n",
      " Results : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       803\n",
      "           1       0.65      0.52      0.57       322\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1125\n",
      "   macro avg       0.73      0.70      0.71      1125\n",
      "weighted avg       0.77      0.78      0.77      1125\n",
      "\n",
      "Accuracy - score :  0.7813333333333333\n",
      "Area under curve :  0.701724124594881 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~leoknauth/116.embed\" height=\"1000px\" width=\"850px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logit_model, logit_graph) = make_model_prediction_coefs(cols = cols, cf = \"coefficients\")\n",
    "logit_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm = 'auto', leaf_size=30,\n",
    "           metric_params = None, n_jobs=-1, n_neighbors = 6, p = 2,\n",
    "           weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knn   = knn.predict(val_X)\n",
    "probabilities_knn = knn.predict_proba(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Classification report: \\n\",classification_report(val_Y ,predictions_knn))\n",
    "print(\"Accuracy Score: \",accuracy_score(val_Y ,predictions_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(val_Y = val_Y, preds = predictions_knn, probs = probabilities_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_SMOTE, train_Y_SMOTE = SMOTE(random_state = 1911).fit_sample(train_X, train_Y)\n",
    "val_X_SMOTE, val_Y_SMOTE = SMOTE(random_state = 1911).fit_sample(val_X, val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________\n",
      "\n",
      " Results : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       803\n",
      "           1       0.74      0.81      0.77       803\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1606\n",
      "   macro avg       0.76      0.76      0.76      1606\n",
      "weighted avg       0.76      0.76      0.76      1606\n",
      "\n",
      "Accuracy - score :  0.7615193026151931\n",
      "Area under curve :  0.7615193026151931 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~leoknauth/110.embed\" height=\"1000px\" width=\"850px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logit_model_smote, logit_graph_smote) = make_model_prediction_coefs(cols = cols, cf = \"coefficients\", \n",
    "                                                                     train_x =train_X_SMOTE, train_y = train_Y_SMOTE, \n",
    "                                                                     test_x = val_X_SMOTE, test_y = val_Y_SMOTE)\n",
    "logit_graph_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :  0.7615193026151931\n",
      "\n",
      "KNN :  0.7098381070983811\n",
      "\n",
      "Support Vector Classifier :  0.7770859277708593\n",
      "\n",
      "Random Forest :  0.7571606475716064\n",
      "\n",
      "Gaussian Naive Bayes :  0.772104607721046\n",
      "\n",
      "Gradient Boost Classifier :  0.8325031133250311\n",
      "\n",
      "Light GBM Classifier :  0.8337484433374845\n",
      "\n",
      "XGBoost Classifier :  0.8356164383561643\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.7615193026151931,\n",
       " 'KNN': 0.7098381070983811,\n",
       " 'Support Vector Classifier': 0.7770859277708593,\n",
       " 'Random Forest': 0.7571606475716064,\n",
       " 'Gaussian Naive Bayes': 0.772104607721046,\n",
       " 'Gradient Boost Classifier': 0.8325031133250311,\n",
       " 'Light GBM Classifier': 0.8337484433374845,\n",
       " 'XGBoost Classifier': 0.8356164383561643}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_baseline_models_AUCs(train_x = train_X_SMOTE, test_x = val_X_SMOTE,\n",
    "                            train_y = train_Y_SMOTE, test_y = val_Y_SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE lead to an increased performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_ADASYN, train_Y_ADASYN = ADASYN(random_state = 1990).fit_sample(train_X, train_Y)\n",
    "val_X_ADASYN, val_Y_ADASYN = ADASYN(random_state = 1990).fit_sample(val_X, val_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________\n",
      "\n",
      " Results : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.63      0.70       803\n",
      "           1       0.69      0.82      0.75       787\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      1590\n",
      "   macro avg       0.74      0.73      0.72      1590\n",
      "weighted avg       0.74      0.73      0.72      1590\n",
      "\n",
      "Accuracy - score :  0.7257861635220125\n",
      "Area under curve :  0.726758455031244 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~leoknauth/112.embed\" height=\"1000px\" width=\"850px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logit_model_adasyn, logit_graph_adasyn) = make_model_prediction_coefs(cols = cols, cf = \"coefficients\", \n",
    "                                                                     train_x =train_X_ADASYN, train_y = train_Y_ADASYN, \n",
    "                                                                     test_x = val_X_ADASYN, test_y = val_Y_ADASYN)\n",
    "logit_graph_adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :  0.726758455031244\n",
      "\n",
      "KNN :  0.6978144220925026\n",
      "\n",
      "Support Vector Classifier :  0.7441527246143353\n",
      "\n",
      "Random Forest :  0.7609211644389449\n",
      "\n",
      "Gaussian Naive Bayes :  0.7491490772373612\n",
      "\n",
      "Light GBM Classifier :  0.8281768969920612\n",
      "\n",
      "XGBoost Classifier :  0.836803220451895\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.726758455031244,\n",
       " 'KNN': 0.6978144220925026,\n",
       " 'Support Vector Classifier': 0.7441527246143353,\n",
       " 'Random Forest': 0.7609211644389449,\n",
       " 'Gaussian Naive Bayes': 0.7491490772373612,\n",
       " 'Light GBM Classifier': 0.8281768969920612,\n",
       " 'XGBoost Classifier': 0.836803220451895}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_baseline_models_AUCs(train_x = train_X_ADASYN, test_x = val_X_ADASYN,\n",
    "                            train_y = train_Y_ADASYN, test_y = val_Y_ADASYN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADASYN doesn't do as well was SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 59.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed: 91.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'loss': ['deviance'], 'learning_rate': [0.05, 0.075, 0.1], 'min_samples_split': array([0.01 , 0.028, 0.046, 0.064, 0.082, 0.1  ]), 'min_samples_leaf': array([0.1 , 0.18, 0.26, 0.34, 0.42, 0.5 ]), 'max_depth': [10, 20], 'max_features': ['sqrt'], 'criterion': ['friedman_mse', 'mae'], 'subsample': [1.0], 'n_estimators': [125]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=True)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameter_grid={\n",
    "#     \"loss\":[\"deviance\"],\n",
    "#     \"learning_rate\": [0.05, 0.075, 0.1],\n",
    "#     \"min_samples_split\": np.linspace(0.01, 0.1, 6),\n",
    "#     \"min_samples_leaf\": np.linspace(0.1, 0.5, 6),\n",
    "#     \"max_depth\":[10,20],\n",
    "#     \"max_features\":[\"sqrt\"],\n",
    "#     \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "#     \"subsample\":[ 1.0],\n",
    "#     \"n_estimators\":[125]\n",
    "#     }\n",
    "# clf = GridSearchCV(GradientBoostingClassifier(), parameter_grid, cv=5, n_jobs=-1,scoring = 'roc_auc', verbose= True)\n",
    "# clf.fit(train_X_SMOTE, train_Y_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9045428039465869"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC_AUC is 0.9045428039465869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_best_params = clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 0.1,\n",
       " 'min_samples_split': 0.082,\n",
       " 'n_estimators': 125,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostClassifier() performs best at\n",
    "\n",
    "{'criterion': 'friedman_mse',\n",
    " 'learning_rate': 0.1,\n",
    " 'loss': 'deviance',\n",
    " 'max_depth': 10,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_leaf': 0.1,\n",
    " 'min_samples_split': 0.082,\n",
    " 'n_estimators': 125,\n",
    " 'subsample': 1.0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ameter_grid={\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.05, 0.075, 0.1],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'min_samples_split': [2, 3],\n",
    "    \"max_depth\":[40,50],\n",
    "    \"max_features\":[\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\"],\n",
    "    \"subsample\":[ 1.0],\n",
    "    \"n_estimators\":[125]\n",
    "    }\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameter_grid, cv=5, n_jobs=-1,scoring = 'roc_auc', verbose= True)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgboost = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=125, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-339-60624c6f0b74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparam_comb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'StratifiedKFold' is not defined"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits = folds, shuffle = True, random_state = 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(xgb, param_distributions = params_xgboost, \n",
    "                                   n_iter = param_comb, scoring = 'roc_auc', \n",
    "                                   n_jobs = -1, cv = skf.split(X,Y), verbose=3, \n",
    "                                   random_state = 2000 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
